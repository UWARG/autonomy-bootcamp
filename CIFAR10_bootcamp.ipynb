{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10_bootcamp.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1gZ3kJQ-zloLlEyjZwKPFpWFP3H5MC3Gu",
      "authorship_tag": "ABX9TyMwIDx0Ra+FA8f6MZe2l1+v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artms-18/computer-vision-bootcamp/blob/master/CIFAR10_bootcamp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh6R_5Rkjn8S"
      },
      "source": [
        "#Computer Vision using a ResNet50 model on the CIFAR10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i9dSqmInuQ2"
      },
      "source": [
        "#importing required libraries\n",
        "\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tarfile\n",
        "import pickle\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
        "from keras.layers import Input, AveragePooling2D\n",
        "from keras.models import Model\n",
        "import tensorflow_datasets as tfds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfyA47Y7CZBy",
        "outputId": "a80014b7-fab9-41c1-94de-a8456c9d33d8"
      },
      "source": [
        "#checking if connected to GPU runtime\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Jun 19 17:05:06 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    22W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfGj1ohDlhUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e0064e4-f6a3-474c-83ca-93c548186cf7"
      },
      "source": [
        "# getting the CIFAR-10 dataset from the built-in tensorflow dataset module\n",
        "\n",
        "(training_images, training_labels), (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGv_bFeRmZ-I"
      },
      "source": [
        "#preprocessing tha CIFAR-10 dataset using the built in preprocessing function\n",
        "\n",
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ye_ah_jUuHcp"
      },
      "source": [
        "## The ResNet50 Model\n",
        "\n",
        "Essentially what is does, is use a series of residual blocks (which take an original input, do some convolutions and then add the original input to the updated one) and stacks them on top of each other, while also reducing the dimensionality of the input every few blocks. It is used to aid in backpropagation wherein usually, there is a vanishing gradient problem, however, the residual blocks help alleviate this issue.\n",
        "\n",
        "Also, I would usually just use tranfer learning to get the model but I feel like thats cheating haha so I just built my own"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b-nNq82xI0w"
      },
      "source": [
        "# Creating a data augmentation layer that will be incorporated into the model (aids in reducing overfitting)\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\")\n",
        "], name = 'data_augmentation')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6nr2z8smY8f"
      },
      "source": [
        "# First define the identity block, where the dimension des not change, but the depth does.\n",
        "# Following the stucture of the ResNet50 model\n",
        "\n",
        "def identity(input, filters):\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args:  \n",
        "    input: the input passed from a previous layer (using the tensorflow functional API)\n",
        "    filters: a tuple containing the respective number of filters being applied in the convolutions\n",
        "\n",
        "  Returns: an output 'x' of which will be passed to another layers within the model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter1, filter2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block (size is kept the same with padding = 'same')\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block \n",
        "  x = Conv2D(filter2, kernel_size= (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  #add the input\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDcf0gERLRjW"
      },
      "source": [
        "def res_conv(input, strides, filters):\n",
        "\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    \n",
        "    input: the input passed from a previous layer\n",
        "    strides: how far the filter moves before being applied again \n",
        "    filters: a tuple containing the number of conv filters being applied to the input\n",
        "  \n",
        "\n",
        "  Returns:\n",
        "\n",
        "    an output with reduced dimensionality of the input shape /2 (following the ResNet50 structure)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  skip = input\n",
        "  filter1, filter2 = filters\n",
        "\n",
        "  #first block\n",
        "  x = Conv2D(filter1, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer=regularizers.l2(0.001))(input)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block\n",
        "  x = Conv2D(filter1, kernel_size = (3,3), strides = (1,1), padding = 'same', kernel_regularizer= regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(filter2, kernel_size = (1,1), strides = (1,1), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  #converting the input tensor to match the dimensionality of the newly changed x (due to changing the strides)\n",
        "  skip = Conv2D(filter2, kernel_size = (1,1), strides = (strides, strides), padding = 'valid', kernel_regularizer = regularizers.l2(0.001))(skip)\n",
        "  skip = BatchNormalization()(skip)\n",
        "\n",
        "  #add\n",
        "  x = Add()([x, skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iniOWd2NYwBn"
      },
      "source": [
        "# finally building the ResNet Model!!\n",
        "\n",
        "from keras.layers import Input, AveragePooling2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, UpSampling2D\n",
        "from keras.models import Model\n",
        "from keras import activations, regularizers\n",
        "\n",
        "\n",
        "def resnet50():\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  Args: None\n",
        "\n",
        "  Returns: the ResNet50 tensorflow model\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  input_image = Input(shape = (32,32,3)) #the way images in CIFAR dataset are stuctured\n",
        "  resize = UpSampling2D(size=(7,7))(input_image)\n",
        "  x = data_augmentation(resize)\n",
        "  x = ZeroPadding2D(padding = (3,3))(x) #to preserve original input size\n",
        "\n",
        "  #step 1: maxpooling (refer to model summary of ResNet50)\n",
        "\n",
        "  #images are scaled to 256x256\n",
        "  x = Conv2D(64, kernel_size = (7,7), strides = (2,2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "  x = MaxPooling2D((3,3), strides = (2,2))(x)\n",
        "\n",
        "  #step 2:\n",
        "\n",
        "  x = res_conv(x, strides = 1, filters = (64, 256))\n",
        "  x = identity(x, filters=(64, 256))\n",
        "  x = identity(x, filters = (64,256))\n",
        "\n",
        "  #step 3:\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "  x = identity(x, filters = (128, 512))\n",
        "\n",
        "  #step 4\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "  x = identity(x, filters = (256, 1024))\n",
        "\n",
        "  #step 5\n",
        "\n",
        "  x = res_conv(x, strides = 2, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "  x = identity(x, filters = (512, 2048))\n",
        "\n",
        "  #model concludes with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2,2), padding = 'same')(x)\n",
        "\n",
        "  #add a flatten layer as dense required this input shape\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(10, activation = 'softmax', kernel_initializer = tf.keras.initializers.he_normal)(x)\n",
        "\n",
        "  model = Model(inputs = input_image, outputs = x, name = 'Resnet50')\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC7Z-pL8pBsl"
      },
      "source": [
        "model = resnet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-gy5HhnnVB5",
        "outputId": "1c1a511e-3bd6-4355-ddf2-06a5002b68ec"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"Resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 224, 224, 3)  0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.image.random_flip_left_right (None, 224, 224, 3)  0           up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           tf.image.random_flip_left_right[0\n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 112, 112, 64) 9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 112, 112, 64) 256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 112, 112, 64) 0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 55, 55, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 55, 55, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 55, 55, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 55, 55, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 55, 55, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 55, 55, 256)  0           batch_normalization_10[0][0]     \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 28, 28, 128)  32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 28, 28, 512)  66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 28, 28, 512)  0           batch_normalization_17[0][0]     \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 28, 28, 512)  0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 28, 128)  65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 28, 28, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 28, 28, 128)  147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 28, 28, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 28, 28, 512)  66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 28, 28, 512)  2048        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 28, 28, 512)  0           batch_normalization_23[0][0]     \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 28, 28, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 14, 14, 256)  131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 14, 14, 256)  1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 14, 14, 256)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 14, 14, 256)  590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 14, 14, 256)  1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 14, 14, 256)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 14, 14, 1024) 263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 14, 14, 1024) 525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 14, 14, 1024) 4096        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 14, 14, 1024) 4096        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_26[0][0]     \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 14, 14, 1024) 0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 14, 14, 256)  262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 14, 14, 256)  1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 14, 14, 256)  0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 14, 14, 256)  590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 14, 14, 256)  1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 14, 14, 256)  0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 14, 14, 1024) 263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 14, 14, 1024) 4096        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_30[0][0]     \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 14, 14, 1024) 0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 14, 14, 256)  262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 14, 14, 256)  1024        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 14, 14, 256)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 14, 14, 256)  590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 14, 14, 256)  1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 14, 14, 256)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 14, 14, 1024) 263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 14, 14, 1024) 4096        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 14, 14, 1024) 0           batch_normalization_33[0][0]     \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 14, 14, 1024) 0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 14, 14, 256)  262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 14, 14, 256)  1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 14, 14, 256)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 14, 14, 256)  590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 14, 14, 256)  1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 14, 14, 256)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 14, 14, 1024) 263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 14, 14, 1024) 4096        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_36[0][0]     \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 14, 14, 1024) 0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 14, 14, 256)  262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 14, 14, 256)  1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 14, 14, 256)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 14, 14, 256)  590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 14, 14, 256)  1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 14, 14, 256)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 14, 14, 1024) 263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 14, 14, 1024) 4096        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_39[0][0]     \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 14, 14, 1024) 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 14, 14, 256)  262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 14, 14, 256)  1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 14, 14, 256)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 14, 14, 256)  590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 14, 14, 256)  1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 14, 14, 256)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 14, 14, 1024) 263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 14, 14, 1024) 4096        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 14, 14, 1024) 0           batch_normalization_42[0][0]     \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 14, 14, 1024) 0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 512)    2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 512)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 512)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 2048)   8192        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 2048)   8192        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 512)    2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 512)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 2048)   8192        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_49[0][0]     \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 512)    2048        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 512)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 512)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 2048)   8192        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 7, 7, 2048)   0           batch_normalization_52[0][0]     \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 32768)        0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           327690      flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,915,402\n",
            "Trainable params: 23,862,282\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFVBG8dQsJjW"
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "#plot_model(model, show_shapes = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZVsrKf3ttaw"
      },
      "source": [
        "## Callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVz1owqftvXU"
      },
      "source": [
        "#defining a callback class\n",
        "#using earlystopping \n",
        "#it basically uses a moving average to see if the loss decreases in the future and stops training if it dosen't, saving the best weights\n",
        "\n",
        "class EarlyStoppingAtMinLoss(keras.callbacks.Callback):\n",
        "    \"\"\"Stop training when the loss is at its min, i.e. the loss stops decreasing.\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None): #is called at the end of each epoch\n",
        "        current = logs.get(\"loss\")\n",
        "        if np.less(current, self.best):\n",
        "            self.best = current\n",
        "            self.wait = 0\n",
        "            # Record the best weights if current results is better (less).\n",
        "            self.best_weights = self.model.get_weights()\n",
        "        else:\n",
        "            self.wait += 1\n",
        "            if self.wait >= self.patience:\n",
        "                self.stopped_epoch = epoch\n",
        "                self.model.stop_training = True\n",
        "                print(\"Restoring model weights from the end of the best epoch.\")\n",
        "                self.model.set_weights(self.best_weights)\n",
        "\n",
        "earlyStopping = EarlyStoppingAtMinLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSeAFkiEsSEw"
      },
      "source": [
        "## Compiling and Fitting the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Ikq_gMtjK_"
      },
      "source": [
        "# preparing the data in tensorflow datasets for accelerated training\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((training_images, training_labels)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_data = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AliwnMIot3g9"
      },
      "source": [
        "#defining the loss, optimizer, and metrics used for compiling the model \n",
        "\n",
        "model.compile(loss = 'sparse_categorical_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001),\n",
        "              metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDo2lbg3uHbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8749efc7-4835-4d2b-b348-21dcb953f90d"
      },
      "source": [
        "#training the model to fit the data over 50 epochs\n",
        "\n",
        "model_history = model.fit(train_data, epochs = 50, validation_data = val_data, callbacks = [earlyStopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 13.9584 - accuracy: 0.5880 - val_loss: 12.1135 - val_accuracy: 0.5877\n",
            "Epoch 2/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 10.2743 - accuracy: 0.6601 - val_loss: 8.7655 - val_accuracy: 0.6480\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 7.4225 - accuracy: 0.7112 - val_loss: 6.5224 - val_accuracy: 0.6801\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 5.5088 - accuracy: 0.7496 - val_loss: 5.0712 - val_accuracy: 0.7038\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 4.2636 - accuracy: 0.7751 - val_loss: 3.9283 - val_accuracy: 0.7353\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 3.3801 - accuracy: 0.8115 - val_loss: 3.2179 - val_accuracy: 0.7611\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 2.7787 - accuracy: 0.8261 - val_loss: 3.7363 - val_accuracy: 0.6146\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 2.3707 - accuracy: 0.8391 - val_loss: 2.3460 - val_accuracy: 0.7972\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 2.0689 - accuracy: 0.8517 - val_loss: 2.1733 - val_accuracy: 0.7766\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.8177 - accuracy: 0.8657 - val_loss: 1.9260 - val_accuracy: 0.8016\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.6386 - accuracy: 0.8742 - val_loss: 1.8637 - val_accuracy: 0.7807\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.4753 - accuracy: 0.8853 - val_loss: 1.6726 - val_accuracy: 0.8005\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.3511 - accuracy: 0.8931 - val_loss: 1.6223 - val_accuracy: 0.7958\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.2482 - accuracy: 0.8981 - val_loss: 1.4712 - val_accuracy: 0.8236\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.1735 - accuracy: 0.9008 - val_loss: 1.5402 - val_accuracy: 0.7896\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.0964 - accuracy: 0.9072 - val_loss: 1.4542 - val_accuracy: 0.7976\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 1.0408 - accuracy: 0.9124 - val_loss: 5.3143 - val_accuracy: 0.5983\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.9866 - accuracy: 0.9158 - val_loss: 1.3985 - val_accuracy: 0.8021\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.9447 - accuracy: 0.9199 - val_loss: 1.2525 - val_accuracy: 0.8306\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.9136 - accuracy: 0.9203 - val_loss: 1.2794 - val_accuracy: 0.8248\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.8749 - accuracy: 0.9239 - val_loss: 1.4849 - val_accuracy: 0.7885\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.8419 - accuracy: 0.9287 - val_loss: 1.5731 - val_accuracy: 0.7664\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.8121 - accuracy: 0.9314 - val_loss: 1.2055 - val_accuracy: 0.8294\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.7851 - accuracy: 0.9356 - val_loss: 1.2069 - val_accuracy: 0.8260\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.7665 - accuracy: 0.9329 - val_loss: 1.4816 - val_accuracy: 0.7868\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.7398 - accuracy: 0.9389 - val_loss: 1.0840 - val_accuracy: 0.8509\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.7297 - accuracy: 0.9376 - val_loss: 1.8262 - val_accuracy: 0.7673\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.7125 - accuracy: 0.9394 - val_loss: 1.2626 - val_accuracy: 0.8223\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6876 - accuracy: 0.9419 - val_loss: 1.2886 - val_accuracy: 0.8041\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6727 - accuracy: 0.9440 - val_loss: 1.1276 - val_accuracy: 0.8419\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6634 - accuracy: 0.9448 - val_loss: 1.1496 - val_accuracy: 0.8272\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6424 - accuracy: 0.9481 - val_loss: 1.1927 - val_accuracy: 0.8255\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6347 - accuracy: 0.9470 - val_loss: 1.0611 - val_accuracy: 0.8461\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6211 - accuracy: 0.9489 - val_loss: 1.1454 - val_accuracy: 0.8384\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6126 - accuracy: 0.9493 - val_loss: 1.1079 - val_accuracy: 0.8487\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.6007 - accuracy: 0.9509 - val_loss: 1.0447 - val_accuracy: 0.8418\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5972 - accuracy: 0.9501 - val_loss: 1.1958 - val_accuracy: 0.8282\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5825 - accuracy: 0.9521 - val_loss: 1.1036 - val_accuracy: 0.8341\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5709 - accuracy: 0.9540 - val_loss: 1.1500 - val_accuracy: 0.8290\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5659 - accuracy: 0.9536 - val_loss: 1.1734 - val_accuracy: 0.8172\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5491 - accuracy: 0.9566 - val_loss: 1.7539 - val_accuracy: 0.8125\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5520 - accuracy: 0.9543 - val_loss: 1.0437 - val_accuracy: 0.8391\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 269s 172ms/step - loss: 0.5401 - accuracy: 0.9556 - val_loss: 1.1286 - val_accuracy: 0.8284\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.5335 - accuracy: 0.9571 - val_loss: 1.0860 - val_accuracy: 0.8404\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.5252 - accuracy: 0.9571 - val_loss: 1.1162 - val_accuracy: 0.8318\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.5088 - accuracy: 0.9611 - val_loss: 1.0807 - val_accuracy: 0.8237\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.5120 - accuracy: 0.9588 - val_loss: 1.0414 - val_accuracy: 0.8403\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.5026 - accuracy: 0.9605 - val_loss: 1.0332 - val_accuracy: 0.8466\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.4991 - accuracy: 0.9599 - val_loss: 1.0828 - val_accuracy: 0.8350\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 270s 172ms/step - loss: 0.4930 - accuracy: 0.9612 - val_loss: 1.0907 - val_accuracy: 0.8250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfi3G3C9J6mP",
        "outputId": "41cc6664-03e6-4f52-d97c-463d69347946"
      },
      "source": [
        " model.save(\"mikas_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mikas_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R1RFVxdoG1dt",
        "outputId": "451f207b-0e97-40c5-bf2b-0d851a39c23a"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('mikas_model/saved_model.pb') \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f903c046-61e3-4dcd-b58f-e10a8f0899c8\", \"saved_model.pb\", 4834081)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePxo24K5jXzn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_metrics(metric_name, title, ylim=1):\n",
        "  plt.title(title)\n",
        "  plt.ylim(0,ylim)\n",
        "  plt.plot(model_history.history[metric_name],color='blue',label=metric_name)\n",
        "  plt.plot(model_history.history['val_' + metric_name],color='green',label='val_' + metric_name)\n",
        "  plt.savefig('acc_per_epoch.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lBjryqmqj_7a",
        "outputId": "0203c276-434f-4cb1-f31c-cd3ee1db5e1c"
      },
      "source": [
        "plot_metrics('accuracy', 'Accuracy')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNVtxWBXuSsO"
      },
      "source": [
        "Evidently, the training was a bit wonky at first, but calmed down after about 30 epochs a began to overfit at around the same place, so in retrospect, the model works best at around 30 epochs with an accuracy of about 94%"
      ]
    }
  ]
}