(ml) rayaq@Rayaqs-MBP computer-vision-bootcamp % python Main.py --epochs 20 --verbose 1
Metal device set to: Apple M1 Pro

systemMemory: 32.00 GB
maxCacheSize: 10.67 GB

2022-04-21 00:11:45.221535: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-04-21 00:11:45.221662: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
Model: "model"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 input_1 (InputLayer)        [(None, 32, 32, 3)]       0         
                                                                 
 batch_normalization (BatchN  (None, 32, 32, 3)        12        
 ormalization)                                                   
                                                                 
 conv2d (Conv2D)             (None, 30, 30, 64)        1792      
                                                                 
 conv2d_1 (Conv2D)           (None, 28, 28, 64)        36928     
                                                                 
 max_pooling2d (MaxPooling2D  (None, 9, 9, 64)         0         
 )                                                               
                                                                 
 dropout (Dropout)           (None, 9, 9, 64)          0         
                                                                 
 conv2d_2 (Conv2D)           (None, 8, 8, 256)         65792     
                                                                 
 conv2d_3 (Conv2D)           (None, 7, 7, 256)         262400    
                                                                 
 max_pooling2d_1 (MaxPooling  (None, 3, 3, 256)        0         
 2D)                                                             
                                                                 
 dropout_1 (Dropout)         (None, 3, 3, 256)         0         
                                                                 
 flatten (Flatten)           (None, 2304)              0         
                                                                 
 dense (Dense)               (None, 512)               1180160   
                                                                 
 dense_1 (Dense)             (None, 128)               65664     
                                                                 
 dense_2 (Dense)             (None, 10)                1290      
                                                                 
=================================================================
Total params: 1,614,038
Trainable params: 1,614,032
Non-trainable params: 6
_________________________________________________________________
None
2022-04-21 00:11:45.648033: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
Epoch 1/20
2022-04-21 00:11:45.877497: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
1563/1563 [==============================] - ETA: 0s - loss: 1.4760 - accuracy: 0.46092022-04-21 00:12:07.504489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.

Epoch 1: val_loss improved from inf to 1.17499, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 1.4760 - accuracy: 0.4609 - val_loss: 1.1750 - val_accuracy: 0.5731 - lr: 0.0010
Epoch 2/20
1561/1563 [============================>.] - ETA: 0s - loss: 1.0504 - accuracy: 0.6319 
Epoch 2: val_loss improved from 1.17499 to 0.94728, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 1.0503 - accuracy: 0.6319 - val_loss: 0.9473 - val_accuracy: 0.6695 - lr: 0.0010
Epoch 3/20
1560/1563 [============================>.] - ETA: 0s - loss: 0.8926 - accuracy: 0.6883 
Epoch 3: val_loss improved from 0.94728 to 0.86636, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 16ms/step - loss: 0.8925 - accuracy: 0.6883 - val_loss: 0.8664 - val_accuracy: 0.7014 - lr: 0.0010
Epoch 4/20
1563/1563 [==============================] - ETA: 0s - loss: 0.7955 - accuracy: 0.7218 
Epoch 4: val_loss improved from 0.86636 to 0.80377, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.7955 - accuracy: 0.7218 - val_loss: 0.8038 - val_accuracy: 0.7193 - lr: 0.0010
Epoch 5/20
1562/1563 [============================>.] - ETA: 0s - loss: 0.7301 - accuracy: 0.7434 
Epoch 5: val_loss improved from 0.80377 to 0.77917, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.7301 - accuracy: 0.7433 - val_loss: 0.7792 - val_accuracy: 0.7371 - lr: 0.0010
Epoch 6/20
1562/1563 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.7627 
Epoch 6: val_loss improved from 0.77917 to 0.75344, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 23s 15ms/step - loss: 0.6754 - accuracy: 0.7627 - val_loss: 0.7534 - val_accuracy: 0.7435 - lr: 0.0010
Epoch 7/20
1561/1563 [============================>.] - ETA: 0s - loss: 0.6227 - accuracy: 0.7829 
Epoch 7: val_loss did not improve from 0.75344
1563/1563 [==============================] - 24s 15ms/step - loss: 0.6228 - accuracy: 0.7828 - val_loss: 0.7731 - val_accuracy: 0.7377 - lr: 0.0010
Epoch 8/20
1561/1563 [============================>.] - ETA: 0s - loss: 0.5783 - accuracy: 0.7958 
Epoch 8: val_loss improved from 0.75344 to 0.72455, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.5783 - accuracy: 0.7957 - val_loss: 0.7245 - val_accuracy: 0.7596 - lr: 0.0010
Epoch 9/20
1562/1563 [============================>.] - ETA: 0s - loss: 0.5521 - accuracy: 0.8040 
Epoch 9: val_loss improved from 0.72455 to 0.71078, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.5521 - accuracy: 0.8040 - val_loss: 0.7108 - val_accuracy: 0.7646 - lr: 0.0010
Epoch 10/20
1562/1563 [============================>.] - ETA: 0s - loss: 0.5108 - accuracy: 0.8213 
Epoch 10: val_loss did not improve from 0.71078
1563/1563 [==============================] - 24s 15ms/step - loss: 0.5109 - accuracy: 0.8213 - val_loss: 0.7142 - val_accuracy: 0.7693 - lr: 0.0010
Epoch 11/20
1560/1563 [============================>.] - ETA: 0s - loss: 0.4804 - accuracy: 0.8288 
Epoch 11: val_loss improved from 0.71078 to 0.70623, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.4807 - accuracy: 0.8287 - val_loss: 0.7062 - val_accuracy: 0.7708 - lr: 0.0010
Epoch 12/20
1563/1563 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.8402 
Epoch 12: val_loss improved from 0.70623 to 0.70287, saving model to model/cifar10_main_model.h5
1563/1563 [==============================] - 24s 15ms/step - loss: 0.4554 - accuracy: 0.8402 - val_loss: 0.7029 - val_accuracy: 0.7735 - lr: 0.0010
Epoch 13/20
1563/1563 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.8495 
Epoch 13: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.4309 - accuracy: 0.8495 - val_loss: 0.7178 - val_accuracy: 0.7735 - lr: 0.0010
Epoch 14/20
1563/1563 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.8575 
Epoch 14: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.4033 - accuracy: 0.8575 - val_loss: 0.7562 - val_accuracy: 0.7746 - lr: 0.0010
Epoch 15/20
1560/1563 [============================>.] - ETA: 0s - loss: 0.3836 - accuracy: 0.8642 
Epoch 15: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.3834 - accuracy: 0.8642 - val_loss: 0.7401 - val_accuracy: 0.7794 - lr: 0.0010
Epoch 16/20
1563/1563 [==============================] - ETA: 0s - loss: 0.3702 - accuracy: 0.8704 
Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.

Epoch 16: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.3702 - accuracy: 0.8704 - val_loss: 0.7738 - val_accuracy: 0.7686 - lr: 0.0010
Epoch 17/20
1562/1563 [============================>.] - ETA: 0s - loss: 0.2416 - accuracy: 0.9155 
Epoch 17: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.2416 - accuracy: 0.9155 - val_loss: 0.7245 - val_accuracy: 0.8008 - lr: 1.0000e-04
Epoch 18/20
1560/1563 [============================>.] - ETA: 0s - loss: 0.1996 - accuracy: 0.9293 
Epoch 18: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.1996 - accuracy: 0.9293 - val_loss: 0.7564 - val_accuracy: 0.8001 - lr: 1.0000e-04
Epoch 19/20
1561/1563 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9346 
Epoch 19: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.1834 - accuracy: 0.9346 - val_loss: 0.7708 - val_accuracy: 0.8019 - lr: 1.0000e-04
Epoch 20/20
1563/1563 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9371 
Epoch 20: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.

Epoch 20: val_loss did not improve from 0.70287
1563/1563 [==============================] - 24s 15ms/step - loss: 0.1762 - accuracy: 0.9371 - val_loss: 0.7687 - val_accuracy: 0.8012 - lr: 1.0000e-04