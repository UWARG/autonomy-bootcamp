{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import numpy as np\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Code for unpacking data, taken from the CIFAR-10 homepage\n",
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "batchNames = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
    "\n",
    "# Training set\n",
    "xTrainRaw = np.empty((0,3072),int)\n",
    "yTrainRaw = np.empty((0))\n",
    "# Loop through the files and create one large training set\n",
    "for name in batchNames:\n",
    "    \n",
    "    trainBatch = unpickle(\"../data/\" + name)\n",
    "    xTrainRaw = np.append(xTrainRaw, trainBatch[b'data'], axis=0)\n",
    "    yTrainRaw = np.append(yTrainRaw, trainBatch[b'labels'], axis=0)\n",
    "\n",
    "test = unpickle('../data/test_batch')\n",
    "print(xTrainRaw.shape)\n",
    "\n",
    "# Test set\n",
    "xTestRaw = test[b'data']\n",
    "yTestRaw = np.asarray(test[b'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label names: [b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n",
      "Data dimensions: (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "# Get data metadata\n",
    "metadata = unpickle('../data/batches.meta')\n",
    "print(\"Label names:\", metadata[b'label_names'])\n",
    "\n",
    "\n",
    "print(\"Data dimensions:\", trainBatch1[b'data'].shape)\n",
    "\n",
    "# Access the dict with a b' prefix\n",
    "# Like this:\n",
    "## batch_1[b'labels']\n",
    "## batch_1[b'data'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch dict contains four elements:\n",
    "- **data**: The image data as Numpy arrays which are fed into a model (i.e. the x value). The data has dimensions 10,000x3,072, that is, 10,000 images with 32x32 pixels * 3 color channels (RGB)\n",
    "- **labels**: The actual labels which the model must successfully classify (i.e. the y value)\n",
    "- batch_label: The name of the batch (e.g. batch 1/2/3/) (not important)\n",
    "- filenames: Name of each image (not important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The x data in its raw form, (50000,3072) for the training set (10000,3072) for the test set, is not suitable for feeding into a model.\n",
    "\n",
    "For a CNN, we should convert the dimensions of each image from a simple row vector (3072) into (width,height,nChannels), which in our case is (32,32,3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = xTrainRaw.reshape(50000, 32,32,3)\n",
    "xTest = xTestRaw.reshape(10000,32,32,3)\n",
    "\n",
    "yTrain = yTrainRaw\n",
    "yTest = yTestRaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                65600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 122,570\n",
      "Trainable params: 122,570\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential CNN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9191 - accuracy: 0.3333 - val_loss: 1.6787 - val_accuracy: 0.3919\n",
      "Epoch 2/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5568 - accuracy: 0.4421 - val_loss: 1.5501 - val_accuracy: 0.4311\n",
      "Epoch 3/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4607 - accuracy: 0.4778 - val_loss: 1.4389 - val_accuracy: 0.4882\n",
      "Epoch 4/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4018 - accuracy: 0.5007 - val_loss: 1.3899 - val_accuracy: 0.5019\n",
      "Epoch 5/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3555 - accuracy: 0.5206 - val_loss: 1.4142 - val_accuracy: 0.4917\n",
      "Epoch 6/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.3101 - accuracy: 0.5374 - val_loss: 1.3729 - val_accuracy: 0.5178\n",
      "Epoch 7/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2794 - accuracy: 0.5478 - val_loss: 1.3770 - val_accuracy: 0.5164\n",
      "Epoch 8/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.2436 - accuracy: 0.5609 - val_loss: 1.3524 - val_accuracy: 0.5185\n",
      "Epoch 9/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2248 - accuracy: 0.5673 - val_loss: 1.2884 - val_accuracy: 0.5539\n",
      "Epoch 10/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.2002 - accuracy: 0.5759 - val_loss: 1.2973 - val_accuracy: 0.5512\n",
      "Epoch 11/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1792 - accuracy: 0.5850 - val_loss: 1.2902 - val_accuracy: 0.5423\n",
      "Epoch 12/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1566 - accuracy: 0.5924 - val_loss: 1.2916 - val_accuracy: 0.5450\n",
      "Epoch 13/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1391 - accuracy: 0.5982 - val_loss: 1.3009 - val_accuracy: 0.5409\n",
      "Epoch 14/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 1.1174 - accuracy: 0.6069 - val_loss: 1.3025 - val_accuracy: 0.5530\n",
      "Epoch 15/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.1056 - accuracy: 0.6106 - val_loss: 1.3196 - val_accuracy: 0.5541\n",
      "Epoch 16/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0850 - accuracy: 0.6192 - val_loss: 1.3447 - val_accuracy: 0.5549\n",
      "Epoch 17/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0615 - accuracy: 0.6267 - val_loss: 1.3945 - val_accuracy: 0.5364\n",
      "Epoch 18/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0473 - accuracy: 0.6324 - val_loss: 1.4084 - val_accuracy: 0.5301\n",
      "Epoch 19/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0383 - accuracy: 0.6346 - val_loss: 1.3537 - val_accuracy: 0.5557\n",
      "Epoch 20/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0145 - accuracy: 0.6424 - val_loss: 1.3429 - val_accuracy: 0.5601\n",
      "Epoch 21/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 1.0037 - accuracy: 0.6462 - val_loss: 1.4332 - val_accuracy: 0.5380\n",
      "Epoch 22/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9855 - accuracy: 0.6545 - val_loss: 1.3728 - val_accuracy: 0.5522\n",
      "Epoch 23/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9735 - accuracy: 0.6604 - val_loss: 1.3822 - val_accuracy: 0.5522\n",
      "Epoch 24/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9693 - accuracy: 0.6603 - val_loss: 1.3872 - val_accuracy: 0.5663\n",
      "Epoch 25/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9455 - accuracy: 0.6681 - val_loss: 1.4095 - val_accuracy: 0.5583\n",
      "Epoch 26/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9290 - accuracy: 0.6742 - val_loss: 1.3967 - val_accuracy: 0.5498\n",
      "Epoch 27/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9168 - accuracy: 0.6791 - val_loss: 1.4397 - val_accuracy: 0.5610\n",
      "Epoch 28/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9057 - accuracy: 0.6828 - val_loss: 1.4986 - val_accuracy: 0.5553\n",
      "Epoch 29/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8888 - accuracy: 0.6900 - val_loss: 1.4697 - val_accuracy: 0.5509\n",
      "Epoch 30/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8846 - accuracy: 0.6907 - val_loss: 1.4618 - val_accuracy: 0.5580\n",
      "Epoch 31/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8765 - accuracy: 0.6932 - val_loss: 1.5492 - val_accuracy: 0.5477\n",
      "Epoch 32/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8735 - accuracy: 0.6960 - val_loss: 1.4690 - val_accuracy: 0.5614\n",
      "Epoch 33/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8458 - accuracy: 0.7028 - val_loss: 1.4900 - val_accuracy: 0.5609\n",
      "Epoch 34/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8437 - accuracy: 0.7041 - val_loss: 1.5960 - val_accuracy: 0.5542\n",
      "Epoch 35/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8290 - accuracy: 0.7091 - val_loss: 1.6388 - val_accuracy: 0.5352\n",
      "Epoch 36/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8286 - accuracy: 0.7101 - val_loss: 1.6716 - val_accuracy: 0.5395\n",
      "Epoch 37/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.8223 - accuracy: 0.7142 - val_loss: 1.6662 - val_accuracy: 0.5450\n",
      "Epoch 38/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8035 - accuracy: 0.7197 - val_loss: 1.7936 - val_accuracy: 0.5406\n",
      "Epoch 39/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7970 - accuracy: 0.7240 - val_loss: 1.7215 - val_accuracy: 0.5387\n",
      "Epoch 40/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7985 - accuracy: 0.7245 - val_loss: 1.7032 - val_accuracy: 0.5468\n",
      "Epoch 41/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7835 - accuracy: 0.7285 - val_loss: 1.8582 - val_accuracy: 0.5352\n",
      "Epoch 42/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7780 - accuracy: 0.7288 - val_loss: 1.8191 - val_accuracy: 0.5457\n",
      "Epoch 43/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7736 - accuracy: 0.7318 - val_loss: 1.9430 - val_accuracy: 0.5291\n",
      "Epoch 44/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7656 - accuracy: 0.7345 - val_loss: 1.6439 - val_accuracy: 0.5554\n",
      "Epoch 45/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7620 - accuracy: 0.7343 - val_loss: 1.8595 - val_accuracy: 0.5414\n",
      "Epoch 46/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7491 - accuracy: 0.7392 - val_loss: 1.8851 - val_accuracy: 0.5355\n",
      "Epoch 47/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7482 - accuracy: 0.7410 - val_loss: 1.8590 - val_accuracy: 0.5408\n",
      "Epoch 48/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7420 - accuracy: 0.7447 - val_loss: 1.8345 - val_accuracy: 0.5482\n",
      "Epoch 49/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7364 - accuracy: 0.7452 - val_loss: 1.8855 - val_accuracy: 0.5395\n",
      "Epoch 50/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7291 - accuracy: 0.7484 - val_loss: 2.0724 - val_accuracy: 0.5229\n",
      "Epoch 51/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7336 - accuracy: 0.7488 - val_loss: 1.8734 - val_accuracy: 0.5474\n",
      "Epoch 52/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7211 - accuracy: 0.7516 - val_loss: 1.8370 - val_accuracy: 0.5306\n",
      "Epoch 53/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7073 - accuracy: 0.7557 - val_loss: 2.0787 - val_accuracy: 0.5325\n",
      "Epoch 54/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7149 - accuracy: 0.7532 - val_loss: 2.1849 - val_accuracy: 0.5340\n",
      "Epoch 55/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7308 - accuracy: 0.7492 - val_loss: 1.9948 - val_accuracy: 0.5345\n",
      "Epoch 56/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.7055 - accuracy: 0.7591 - val_loss: 1.9340 - val_accuracy: 0.5351\n",
      "Epoch 57/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6999 - accuracy: 0.7594 - val_loss: 1.9850 - val_accuracy: 0.5366\n",
      "Epoch 58/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6775 - accuracy: 0.7667 - val_loss: 2.0846 - val_accuracy: 0.5295\n",
      "Epoch 59/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6896 - accuracy: 0.7627 - val_loss: 1.9541 - val_accuracy: 0.5319\n",
      "Epoch 60/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6849 - accuracy: 0.7656 - val_loss: 2.0757 - val_accuracy: 0.5401\n",
      "Epoch 61/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6919 - accuracy: 0.7633 - val_loss: 2.0603 - val_accuracy: 0.5376\n",
      "Epoch 62/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6733 - accuracy: 0.7689 - val_loss: 2.2788 - val_accuracy: 0.5339\n",
      "Epoch 63/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6789 - accuracy: 0.7674 - val_loss: 2.0876 - val_accuracy: 0.5414\n",
      "Epoch 64/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6915 - accuracy: 0.7645 - val_loss: 2.0902 - val_accuracy: 0.5290\n",
      "Epoch 65/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6540 - accuracy: 0.7755 - val_loss: 2.1768 - val_accuracy: 0.5426\n",
      "Epoch 66/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6554 - accuracy: 0.7752 - val_loss: 2.3902 - val_accuracy: 0.5289\n",
      "Epoch 67/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6801 - accuracy: 0.7681 - val_loss: 2.2677 - val_accuracy: 0.5193\n",
      "Epoch 68/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6588 - accuracy: 0.7763 - val_loss: 2.3149 - val_accuracy: 0.5279\n",
      "Epoch 69/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6557 - accuracy: 0.7777 - val_loss: 2.1781 - val_accuracy: 0.5277\n",
      "Epoch 70/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6533 - accuracy: 0.7784 - val_loss: 2.2777 - val_accuracy: 0.5279\n",
      "Epoch 71/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6489 - accuracy: 0.7812 - val_loss: 2.2567 - val_accuracy: 0.5226\n",
      "Epoch 72/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6605 - accuracy: 0.7783 - val_loss: 2.0693 - val_accuracy: 0.5310\n",
      "Epoch 73/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6401 - accuracy: 0.7825 - val_loss: 2.1520 - val_accuracy: 0.5221\n",
      "Epoch 74/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6408 - accuracy: 0.7825 - val_loss: 2.2469 - val_accuracy: 0.5283\n",
      "Epoch 75/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6422 - accuracy: 0.7828 - val_loss: 2.3429 - val_accuracy: 0.5301\n",
      "Epoch 76/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6367 - accuracy: 0.7838 - val_loss: 2.2338 - val_accuracy: 0.5243\n",
      "Epoch 77/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6421 - accuracy: 0.7831 - val_loss: 2.3954 - val_accuracy: 0.5365\n",
      "Epoch 78/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6400 - accuracy: 0.7860 - val_loss: 2.4663 - val_accuracy: 0.5128\n",
      "Epoch 79/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6632 - accuracy: 0.7784 - val_loss: 2.2024 - val_accuracy: 0.5189\n",
      "Epoch 80/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6200 - accuracy: 0.7914 - val_loss: 2.2716 - val_accuracy: 0.5308\n",
      "Epoch 81/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6401 - accuracy: 0.7866 - val_loss: 2.5266 - val_accuracy: 0.5274\n",
      "Epoch 82/1000\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6271 - accuracy: 0.7893 - val_loss: 2.3277 - val_accuracy: 0.5285\n",
      "Epoch 83/1000\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.6303 - accuracy: 0.7891 - val_loss: 2.5469 - val_accuracy: 0.5283\n",
      "Epoch 84/1000\n",
      "1495/1563 [===========================>..] - ETA: 0s - loss: 0.6182 - accuracy: 0.7920"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(xTrain, yTrain, epochs=1000, \n",
    "                    validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
