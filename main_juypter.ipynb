{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a starter file to get you going. You may also include other files if you feel it's necessary.\n",
    "\n",
    "Make sure to follow the code convention described here:\n",
    "https://github.com/UWARG/computer-vision-python/blob/main/README.md#naming-and-typing-conventions\n",
    "\n",
    "Hints:\n",
    "* The internet is your friend! Don't be afraid to search for tutorials/intros/etc.\n",
    "* We suggest using a convolutional neural network.\n",
    "* TensorFlow Keras has the CIFAR-10 dataset as a module, so you don't need to manually download and unpack it.\n",
    "\"\"\"\n",
    "\n",
    "# Import whatever libraries/modules you need\n",
    "\n",
    "from ast import arg\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from re import L\n",
    "from zmq import device\n",
    "\n",
    "# Your working code here\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        #create convolutional layers\n",
    "        super().__init__()\n",
    "        #kernel size of 5\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        #flatten to go through linear layers\n",
    "        nn.Flatten()\n",
    "        self.fc1 = nn.Linear(800, 512)\n",
    "        #10 classes\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    def convs(self, x):\n",
    "        #maxpooling simplifies the picture with window size of 2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, 800)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        #run through the neural network\n",
    "        return F.softmax(x, dim = 1)\n",
    "\n",
    "def organize_data():\n",
    "    #manage data from Tf dataset\n",
    "    RGB_TO_GREY = [0.299, 0.587, 0.114]\n",
    "    PIXEL_VALUE = 255.0\n",
    "    #load CIFAR10 data set into np arrays\n",
    "    (xTrain, yTrain), (xTest, yTest) = tf.keras.datasets.cifar10.load_data()\n",
    "    #grey scale\n",
    "    xTrain = np.dot(xTrain, RGB_TO_GREY)\n",
    "    #conver to tensor\n",
    "    xTrain = torch.Tensor(xTrain) \n",
    "    #convert to decimal values from 0-1\n",
    "    xTrain = xTrain/PIXEL_VALUE\n",
    "    #repeat for test set\n",
    "    xTest = np.dot(xTest, RGB_TO_GREY)\n",
    "    xTest = torch.Tensor(xTest) \n",
    "    xTest = xTest/PIXEL_VALUE\n",
    "    #convert to tensor\n",
    "    yTrain = torch.Tensor(yTrain)\n",
    "    yTest = torch.Tensor(yTest)\n",
    "    #make a new tensor of correct dimensions to input both images and labels into loss function\n",
    "    ytrain = torch.zeros(len(xTrain), 10)\n",
    "    ytest = torch.zeros(len(xTest), 10)\n",
    "    #input correct value into correct index value for entire tensor\n",
    "    for i in range(len(xTrain)):\n",
    "        ytrain[i][(yTrain[i] - 1).long()] = 1.0\n",
    "    for i in range(len(xTest)):\n",
    "        ytest[i][(yTest[i] - 1).long()] = 1.0\n",
    "    yTrain = ytrain\n",
    "    yTest = ytest\n",
    "    return xTrain, yTrain, xTest, yTest\n",
    "\n",
    "def select_device():\n",
    "    #choose device if you can use nvidea gpu\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "def train(net, xTrain, yTrain, xTest, yTest, device, loss_function, optimizer, EPOCHS, BATCH_SIZE, MODEL_NAME): \n",
    "    #use for graph later\n",
    "    with open(\"model.log\", \"a\") as f: \n",
    "        for epoch in range(EPOCHS):\n",
    "            #use for loading bar\n",
    "            for i in tqdm(range(0, len(xTrain), BATCH_SIZE)): \n",
    "                #array splice for each batch size\n",
    "                #32, 32 because cnn can take 2d array\n",
    "                x_batch = xTrain[i:i+BATCH_SIZE].view(-1, 1, 32, 32)\n",
    "                y_batch = yTrain[i:i+BATCH_SIZE]\n",
    "                #send to gpu\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                #get accuracy and loss through helper function\n",
    "                acc, loss = fwd_pass(x_batch, y_batch, net, loss_function, optimizer, train = True)\n",
    "                if i % 10 == 0:\n",
    "                    #for the graph\n",
    "                    val_acc, val_loss = test(xTest, yTest, net, loss_function, optimizer, device, size = 100)\n",
    "                    f.write(f\"{MODEL_NAME}, {epoch}, {round(float(acc), 2)}, {round(float(loss), 4)}, {round(float(val_acc), 2)}, {round(float(val_loss), 4)}\\n\")\n",
    "            print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "def batch_test(net, xTest, yTest, device, BATCH_SIZE): \n",
    "    with torch.no_grad():\n",
    "        #test a batch of the test tensor\n",
    "        x_batch = xTest[:BATCH_SIZE].view(-1, 1, 32, 32)\n",
    "        y_batch = yTest[:BATCH_SIZE]\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        #zero gradient\n",
    "        net.zero_grad()\n",
    "        #output of the cnn\n",
    "        outputs = net(x_batch)\n",
    "        #find matches of outputs and labels\n",
    "        matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y_batch)]\n",
    "        #find accuracy of matches\n",
    "        acc = matches.count(True)/len(matches)\n",
    "        print(\"Test Accuracy: \", round(acc, 3))\n",
    "\n",
    "def fwd_pass(X, y, net, loss_function, optimizer, train = False):\n",
    "    if train:\n",
    "        #if we are training, zero the gradient\n",
    "        net.zero_grad()\n",
    "    #outputs of the cnn\n",
    "    outputs = net(X)\n",
    "    #find matches of outputs and labels\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    #find accuracy of matches\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    #run through loss function \n",
    "    loss = loss_function(outputs, y)\n",
    "    if train: \n",
    "        #if we are training, optimize the network\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return acc, loss\n",
    "\n",
    "def test(xTest, yTest, net, loss_function, optimizer, device, size = 32):\n",
    "    #test for points on the graph\n",
    "    X, y = xTest[:size], yTest[:size]\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1, 1, 32, 32).to(device), y.to(device), net, loss_function, optimizer)\n",
    "    return val_acc, val_loss\n",
    "\n",
    "\n",
    "def create_acc_loss_graph(model_name, loss_or_acc):\n",
    "    contents = open(\"model.log\", \"r\").read().split(\"\\n\")\n",
    "    epochs = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    test_losses = []\n",
    "    for c in contents: \n",
    "        if model_name in c:\n",
    "            #read the name of the model\n",
    "            name, epoch, acc, loss, test_acc, test_loss = c.split(\",\")\n",
    "            epochs.append(float(epoch))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            test_accs.append(float(test_acc))\n",
    "            test_losses.append(float(test_loss))\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    #make the correct graph \n",
    "    if(loss_or_acc == \"acc\"):\n",
    "        ax1.plot(epochs, accuracies, label = \"acc\")\n",
    "        ax1.plot(epochs, test_accs, label = \"test_acc\")\n",
    "    elif(loss_or_acc == \"loss\"):\n",
    "        ax1.plot(epochs, losses, label = \"loss\")\n",
    "        ax1.plot(epochs, test_losses, label = \"test_loss\")\n",
    "    ax1.legend(loc = 2)\n",
    "    plt.show() \n",
    "\n",
    "def main():\n",
    "    #make all objects \n",
    "    device = select_device()\n",
    "    net = Net().to(device)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "    loss_function = nn.MSELoss()\n",
    "    xTrain, yTrain, xTest, yTest = organize_data()\n",
    "    #make constants\n",
    "    MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "    BATCH_SIZE = 100\n",
    "    EPOCHS = 10  \n",
    "    #train the model\n",
    "    train(net, xTrain, yTrain, xTest, yTest, device, loss_function, optimizer, EPOCHS, BATCH_SIZE, MODEL_NAME)\n",
    "    #test the model\n",
    "    batch_test(net, xTest, yTest, device, BATCH_SIZE)\n",
    "    style.use(\"ggplot\")\n",
    "    model_name = MODEL_NAME\n",
    "    #show the accuracy/loss\n",
    "    create_acc_loss_graph(model_name, \"acc\")\n",
    "\n",
    "#run the program\n",
    "main()\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8cd98ac651c668ce2c6203d75b23f2d5bc0a45f06efaf825f1ea3a340dc3a78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
