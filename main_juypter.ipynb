{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 32]' is invalid for input of size 3072",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ethan\\OneDrive\\Documents\\GitHub\\computer-vision-bootcamp\\main_juypter.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=119'>120</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m val_acc, val_loss\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=121'>122</a>\u001b[0m \u001b[39m#train(net)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=122'>123</a>\u001b[0m \u001b[39m#batch_test(net)\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=123'>124</a>\u001b[0m \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=124'>125</a>\u001b[0m \u001b[39m#style.use(\"ggplot\")\u001b[39;00m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=125'>126</a>\u001b[0m \u001b[39m#model_name = MODEL_NAME\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=127'>128</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(x_train[\u001b[39m2\u001b[39;49m]\u001b[39m.\u001b[39;49mview(\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m))\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=128'>129</a>\u001b[0m plt\u001b[39m.\u001b[39mshow\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ethan/OneDrive/Documents/GitHub/computer-vision-bootcamp/main_juypter.ipynb#ch0000000?line=130'>131</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_acc_loss_graph\u001b[39m(model_name):\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[32, 32]' is invalid for input of size 3072"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a starter file to get you going. You may also include other files if you feel it's necessary.\n",
    "\n",
    "Make sure to follow the code convention described here:\n",
    "https://github.com/UWARG/computer-vision-python/blob/main/README.md#naming-and-typing-conventions\n",
    "\n",
    "Hints:\n",
    "* The internet is your friend! Don't be afraid to search for tutorials/intros/etc.\n",
    "* We suggest using a convolutional neural network.\n",
    "* TensorFlow Keras has the CIFAR-10 dataset as a module, so you don't need to manually download and unpack it.\n",
    "\"\"\"\n",
    "\n",
    "# Import whatever libraries/modules you need\n",
    "\n",
    "from ast import arg\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from re import L\n",
    "\n",
    "from zmq import device\n",
    "\n",
    "\n",
    "# Your working code here\n",
    "REBUILD_DATA = False\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = torch.Tensor(x_train) #play around with these since loss input n output rnt the same\n",
    "y_train = torch.Tensor(y_train)\n",
    "x_test = torch.Tensor(x_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "#x_train = x_train.view(-1, 32, 32)\n",
    "#x_test = x_test.view(-1, 32, 32)\n",
    "#x_train = x_train/255.0\n",
    "#x_test = x_test/255.0 \n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 5)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        x = torch.randn(32, 32).view(-1, 1, 32, 32)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "    def convs(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim = 1)\n",
    "\n",
    "\n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "MODEL_NAME = f\"model-{int(time.time())}\"\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 3 \n",
    "\n",
    "def train(net): \n",
    "    with open(\"model.log\", \"a\") as f: \n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(x_train), BATCH_SIZE)): \n",
    "                x_batch = x_train[i:i+BATCH_SIZE].view(-1, 1, 32, 32)\n",
    "                y_batch = y_train[i:i+BATCH_SIZE]\n",
    "                x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "                acc, loss = fwd_pass(x_batch, y_batch, train = True)\n",
    "                if i % 10 == 0:\n",
    "                    val_acc, val_loss = test(size = 100)\n",
    "                    f.write(f\"{MODEL_NAME}, {round(time.time(), 3)}, {round(float(acc), 2)}, {round(float(loss), 4)}, {round(float(val_acc), 2)}, {round(float(val_loss), 4)}\\n\")\n",
    "            print(f\"Epoch: {epoch}. Loss: {loss}\")\n",
    "\n",
    "def batch_test(net): \n",
    "    with torch.no_grad():\n",
    "        x_batch = x_test[:BATCH_SIZE].view(-1, 1, 32, 32)\n",
    "        y_batch = y_test[:BATCH_SIZE]\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        net.zero_grad()\n",
    "        outputs = net(x_batch)\n",
    "        matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y_batch)]\n",
    "        acc = matches.count(True)/len(matches) #add if statement\n",
    "        print(\"Test Accuracy: \", round(acc, 3))\n",
    "\n",
    "def fwd_pass(X, y, train = False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches) #add if statement\n",
    "    loss = loss_function(outputs, y)\n",
    "    if train: \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return acc, loss\n",
    "\n",
    "def test(size = 32):\n",
    "    X, y = x_test[:size], y_test[:size]\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1, 1, 32, 32).to(device), y.to(device))\n",
    "    return val_acc, val_loss\n",
    "\n",
    "#train(net)\n",
    "#batch_test(net)\n",
    "\n",
    "#style.use(\"ggplot\")\n",
    "#model_name = MODEL_NAME\n",
    "\n",
    "plt.imshow(x_train[1].view(32, 32))\n",
    "plt.show\n",
    "\n",
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split(\"/n\")\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    test_losses = []\n",
    "    for c in contents: \n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, test_acc, test_loss = c.split(\",\")\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            test_accs.append(float(test_acc))\n",
    "            test_losses.append(float(test_loss))\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (0,0), sharex = ax1)\n",
    "    ax1.plot(times, accuracies, label = \"acc\")\n",
    "    ax1.plot(times, test_accs, label = \"test_acc\")\n",
    "    ax1.legend(loc = 2)\n",
    "    ax2.plot(times, losses, label = \"loss\")\n",
    "    ax2.plot(times, test_losses, label = \"test_loss\")\n",
    "    plt.show() \n",
    "\n",
    "#create_acc_loss_graph(model_name)\n",
    "\n",
    "\n",
    "        \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e51871c569916b212a5169136257eb9b772996936338bc66e712417a39169ea3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
