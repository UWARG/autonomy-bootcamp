{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c88ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:16.698385: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-03 14:56:16.698403: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c3cd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    \"\"\"\n",
    "    Loads CIFAR-10 dataset then returns the train and test set\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple : (xTrain,yTrain), (xTest,yTest)\n",
    "        Returns normalized CIFAR-10 train and test data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Model / data parameters\n",
    "    num_classes = 10\n",
    "    input_shape = (36, 36, 1)\n",
    "\n",
    "    # the data, split between train and test sets\n",
    "    (xTrain, yTrain), (xTest, yTest) = keras.datasets.mnist.load_data()\n",
    "\n",
    "    # Scale images to the [0, 1] range\n",
    "    xTrain = xTrain.astype(\"float32\") / 255\n",
    "    xTest = xTest.astype(\"float32\") / 255\n",
    "    # Make sure images have shape (28, 28, 1)\n",
    "    xTrain = np.expand_dims(xTrain, -1)\n",
    "    xTest = np.expand_dims(xTest, -1)\n",
    "    print(\"xTrain shape:\", xTrain.shape)\n",
    "    print(xTrain.shape[0], \"train samples\")\n",
    "    print(xTest.shape[0], \"test samples\")\n",
    "    \n",
    "    return xTrain, yTrain, xTest, yTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34d241f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(xTrain):\n",
    "    \"\"\"\n",
    "    Train model with covnets, using sequential model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xTrain:tensor\n",
    "        Training tensor set containing the loaded and processed CIFAR10 data\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    model : keras.engine.sequential.Sequential\n",
    "        the feature cconvolutional \n",
    "    \"\"\"\n",
    "    \n",
    "    model = tf.keras.Sequential(\n",
    "        [\n",
    "            layers.Conv2D(filters = 64, kernel_size = (3,3), activation = \"relu\", input_shape = xTrain.shape[1:]),\n",
    "            layers.MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "            layers.Conv2D(filters = 128, kernel_size = (3,3), activation = \"relu\"),\n",
    "            layers.MaxPooling2D(pool_size = (2,2)),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128),\n",
    "            layers.Activation(\"relu\"),\n",
    "\n",
    "            #Softmax output, appropriate for multilabel CV problem\n",
    "            layers.Dense(10),\n",
    "            layers.Activation(\"softmax\"),\n",
    "        ]\n",
    "        \n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f441adf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(historyTrain, EPOCHS, model, xTest, yTest):\n",
    "    \"\"\"\n",
    "    Continue from here\n",
    "    plots training loss and accuraccy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    historyTrain : keras.callbacks.History\n",
    "    EPOCHS : int\n",
    "    model : keras.engine.sequential.Sequential\n",
    "        the feature cconvolutional \n",
    "    xTrain: tensor\n",
    "    yTrain: tensor\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    lossTrain = historyTrain.history['loss']\n",
    "    accTrain = historyTrain.history['accuracy']\n",
    "    epochs = range(1, EPOCHS+1)\n",
    "\n",
    "\n",
    "    plt.plot(epochs, lossTrain, 'g', label='Training Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(epochs, accTrain, 'b', label='Training Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    valLoss, valAcc = model.evaluate(xTest, yTest)\n",
    "    print(\"Validation loss: \", valLoss, \"\\nValidation Accuracy: \", valAcc*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e108f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Continue from here\n",
    "    plots training loss and accuraccy\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    BATCH_SIZE = 128\n",
    "    EPOCHS = 15\n",
    "    \n",
    "    xTrain, yTrain, xTest, yTest = process_data()\n",
    "    \n",
    "    model = train_model(xTrain)\n",
    "\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "    historyTrain = model.fit(xTrain, yTrain, batch_size = BATCH_SIZE, epochs = EPOCHS)\n",
    "    \n",
    "    score = model.evaluate(xTest, yTest, verbose = 0)\n",
    "    \n",
    "    plot_data(historyTrain, EPOCHS, model, xTest, yTest)\n",
    "    \n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee93ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xTrain shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:22.283421: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-03-03 14:56:22.283479: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (jacky-GL503VD): /proc/driver/nvidia/version does not exist\n",
      "2022-03-03 14:56:22.284942: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:22.363990: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 188160000 exceeds 10% of free system memory.\n",
      "2022-03-03 14:56:23.152612: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22151168 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  1/469 [..............................] - ETA: 5:56 - loss: 2.2950 - accuracy: 0.1641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 14:56:23.406547: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22151168 exceeds 10% of free system memory.\n",
      "2022-03-03 14:56:23.499985: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22151168 exceeds 10% of free system memory.\n",
      "2022-03-03 14:56:23.678694: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 22151168 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 42s 87ms/step - loss: 0.1913 - accuracy: 0.9423\n",
      "Epoch 2/15\n",
      "469/469 [==============================] - 41s 87ms/step - loss: 0.0610 - accuracy: 0.9811\n",
      "Epoch 3/15\n",
      "336/469 [====================>.........] - ETA: 11s - loss: 0.0442 - accuracy: 0.9860"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c57e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c9ab5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
